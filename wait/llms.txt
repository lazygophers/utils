# wait - Timeout, Retry, and Rate Limiting Utilities

> 这是 wait 目录的 llms.txt 文件，用于帮助语言模型理解该目录的结构和内容。


这是 wait 目录的 llms.txt 文件，用于帮助语言模型理解该目录的结构和内容。


The wait package provides utilities for controlling concurrent operations, implementing timeouts, retry mechanisms, and rate limiting using semaphore pools and wait groups.

## Key Features
- Named semaphore pools for concurrent operation control
- Enhanced wait groups with timeout support
- Asynchronous operation management with result handling
- Built-in rate limiting capabilities
- Thread-safe operations across all functions
- Multiple pool management with atomic operations

## Core Functions

### Semaphore Pool Operations
- Lock(key string, max int) - Acquire semaphore (creates pool if needed)
- Unlock(key string) - Release semaphore
- TryLock(key string, max int) bool - Non-blocking acquire attempt
- LockWithTimeout(key string, max int, timeout time.Duration) bool - Acquire with timeout

### Pool Management
- NewPool(key string, max int) - Create named semaphore pool
- GetPool(key string) *Pool - Retrieve existing pool
- GetPoolDepth(key string) int - Get current pool usage
- DestroyPool(key string) - Remove pool and release resources

### Multiple Pool Operations
- LockMultiple(keys []string, maxes []int) - Atomic multi-pool lock
- UnlockMultiple(keys []string) - Unlock multiple pools
- TryLockMultiple(keys []string, maxes []int) bool - Non-blocking multi-lock

### Wait Group Operations
- NewGroup() *Group - Create enhanced wait group
- Group.Add(delta int) - Add to counter
- Group.Done() - Decrement counter
- Group.Wait() - Wait for completion
- Group.WaitTimeout(timeout time.Duration) bool - Wait with timeout
- Group.WaitContext(ctx context.Context) error - Context-aware wait

### Async Operations
- Async(fn func() (interface{}, error)) *AsyncResult - Execute asynchronously
- AsyncWithContext(ctx context.Context, fn func() (interface{}, error)) *AsyncResult
- AsyncResult.Get() (interface{}, error) - Get result (blocking)
- AsyncResult.GetWithTimeout(timeout time.Duration) (interface{}, error) - Get with timeout
- AsyncResult.IsReady() bool - Check if completed
- AsyncResult.Cancel() - Cancel operation

## Pool Type Methods
- Pool.Lock() - Acquire semaphore
- Pool.Unlock() - Release semaphore
- Pool.TryLock() bool - Non-blocking acquire
- Pool.LockWithTimeout(timeout time.Duration) bool - Timed acquire
- Pool.Depth() int - Current usage
- Pool.Cap() int - Maximum capacity

## Usage Examples

```go
import "github.com/lazygophers/utils/wait"

// Rate limiting HTTP requests
poolName := "api_requests"
maxConcurrent := 5

for _, url := range urls {
    go func(u string) {
        wait.Lock(poolName, maxConcurrent)
        defer wait.Unlock(poolName)

        // Make HTTP request
        resp, err := http.Get(u)
        // Handle response...
    }(url)
}

// Enhanced wait group with timeout
group := wait.NewGroup()
for i := 0; i < 5; i++ {
    group.Add(1)
    go func(id int) {
        defer group.Done()
        // Perform work...
    }(i)
}

if group.WaitTimeout(5 * time.Second) {
    fmt.Println("All tasks completed")
} else {
    fmt.Println("Timeout reached")
}

// Asynchronous operations
operation := func() (interface{}, error) {
    time.Sleep(2 * time.Second)
    return "result", nil
}

asyncResult := wait.Async(operation)
// Do other work...
result, err := asyncResult.GetWithTimeout(5 * time.Second)

// Database connection pool management
wait.NewPool("db_connections", 10)
if wait.LockWithTimeout("db_connections", 10, 5*time.Second) {
    defer wait.Unlock("db_connections")
    // Execute database query
}

// Multiple resource locking
wait.LockMultiple([]string{"cpu_pool", "memory_pool"}, []int{2, 4})
defer wait.UnlockMultiple([]string{"cpu_pool", "memory_pool"})
// Use both CPU and memory intensive resources
```

## Implementation Details
- Channel-based semaphores for efficient blocking/unblocking
- Global pool map with read-write mutex protection
- Lock-free pool depth checking where possible
- Automatic pool creation on first use
- Graceful handling of nil pools and edge cases

## Performance Characteristics
- O(1) semaphore acquire/release operations
- Minimal memory overhead per pool
- Efficient buffered channel implementation
- Supports thousands of concurrent operations
- Lock-free operations for read-heavy workloads

## Use Cases
- **Rate Limiting**: API request throttling, resource access control
- **Resource Pools**: Database connections, worker threads, memory buffers
- **Batch Processing**: Concurrent task processing with limits
- **Service Protection**: Prevent resource exhaustion in microservices
- **Background Workers**: Controlled parallel processing
- **Circuit Breaking**: Combine with hystrix for fault tolerance

## Error Handling
The package uses panic-free design patterns with timeout-based operations:

```go
// Safe operations that won't panic
if wait.TryLock("resource", 10) {
    defer wait.Unlock("resource")
    // Use resource
} else {
    // Handle failure to acquire
}

// Timeout-based operations
if wait.LockWithTimeout("resource", 10, 5*time.Second) {
    defer wait.Unlock("resource")
    // Use resource
} else {
    // Handle timeout
}
```

## Thread Safety
All operations are goroutine-safe. Multiple goroutines can safely:
- Access the same pools concurrently
- Create pools with the same name
- Query pool status
- Lock/unlock operations

This package is essential for applications requiring controlled concurrency and resource management.